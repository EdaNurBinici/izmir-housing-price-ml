"""
Model eÄŸitim modÃ¼lÃ¼ - Senior seviyesinde refactor edilmiÅŸ versiyon
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer, TransformedTargetRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import joblib
from pathlib import Path
from typing import Dict, Any, Tuple
import logging

from .config_loader import ConfigLoader
from .logger_setup import setup_logging, get_logger
from .data_processor import DataProcessor
from .exceptions import DataLoadError, ModelLoadError

# Logging'i baÅŸlat
setup_logging()
logger = get_logger(__name__)


class ModelTrainer:
    """Model eÄŸitim sÄ±nÄ±fÄ±"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """
        Model trainer'Ä± baÅŸlatÄ±r
        
        Args:
            config_path: Config dosyasÄ± yolu
        """
        self.config = ConfigLoader(config_path)
        self.data_processor = DataProcessor(self.config)
        self.model = None
        self.pipeline = None
        
    def load_data(self) -> pd.DataFrame:
        """
        Veriyi yÃ¼kler
        
        Returns:
            Ham veri DataFrame
            
        Raises:
            DataLoadError: Veri yÃ¼kleme hatasÄ±
        """
        try:
            data_path = self.config.get_data_path("raw_data")
            file_path = Path(data_path)
            
            if not file_path.exists():
                file_path = Path(__file__).parent.parent / data_path
                if not file_path.exists():
                    raise FileNotFoundError(f"Veri dosyasÄ± bulunamadÄ±: {data_path}")
            
            logger.info(f"Veri yÃ¼kleniyor: {file_path}")
            df = pd.read_csv(file_path)
            logger.info(f"Veri yÃ¼klendi: {len(df)} satÄ±r")
            return df
            
        except Exception as e:
            logger.error(f"Veri yÃ¼kleme hatasÄ±: {e}")
            raise DataLoadError(f"Veri yÃ¼klenemedi: {e}")
    
    def prepare_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """
        Veriyi model eÄŸitimi iÃ§in hazÄ±rlar
        
        Args:
            df: Ham veri DataFrame
            
        Returns:
            X (features) ve y (target) tuple'Ä±
        """
        logger.info("Veri hazÄ±rlanÄ±yor...")
        
        # Veriyi temizle
        df = self.data_processor.clean_data(df, for_training=True)
        
        # Gerekli sÃ¼tunlarÄ± oluÅŸtur
        if 'room' in df.columns and 'salon' in df.columns:
            df['toplam_oda'] = df['room'] + df['salon']
        
        # Gereksiz sÃ¼tunlarÄ± kaldÄ±r
        df = df.drop(columns=['province', 'room', 'salon'], errors='ignore')
        
        # Target encoding iÃ§in ilÃ§e skorunu hesapla
        df['birim_fiyat'] = df['price'] / df['area']
        ilce_degerleri = df.groupby('district')['birim_fiyat'].median()
        df['ilce_skoru'] = df['district'].map(ilce_degerleri)
        df = df.drop(columns=['birim_fiyat'])
        
        # X ve y'yi ayÄ±r
        X = df.drop('price', axis=1)
        y = df['price']
        
        logger.info(f"HazÄ±rlanan veri: {len(X)} satÄ±r, {len(X.columns)} Ã¶zellik")
        
        return X, y, ilce_degerleri
    
    def build_pipeline(self) -> Pipeline:
        """
        Model pipeline'Ä±nÄ± oluÅŸturur
        
        Returns:
            Sklearn Pipeline
        """
        logger.info("Model pipeline'Ä± oluÅŸturuluyor...")
        
        model_config = self.config.get_model_config()
        
        categorical_features = ['district', 'left']
        numerical_features = ['area', 'age', 'toplam_oda', 'ilce_skoru']
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', Pipeline(steps=[
                    ('imputer', SimpleImputer(strategy='median')),
                    ('scaler', StandardScaler())
                ]), numerical_features),
                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
            ]
        )
        
        hgb_model = HistGradientBoostingRegressor(
            max_iter=model_config.get('max_iter', 500),
            learning_rate=model_config.get('learning_rate', 0.05),
            max_depth=model_config.get('max_depth', 10),
            l2_regularization=model_config.get('l2_regularization', 0.1),
            random_state=model_config.get('random_state', 42)
        )
        
        model = TransformedTargetRegressor(
            regressor=hgb_model,
            func=np.log1p,
            inverse_func=np.expm1
        )
        
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('model', model)
        ])
        
        self.pipeline = pipeline
        return pipeline
    
    def train(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:
        """
        Modeli eÄŸitir
        
        Args:
            X: Feature matrix
            y: Target vector
            
        Returns:
            Model metrikleri
        """
        logger.info("Model eÄŸitiliyor...")
        
        test_size = self.config.get_model_config().get('test_size', 0.2)
        random_state = self.config.get_model_config().get('random_state', 42)
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        self.pipeline.fit(X_train, y_train)
        
        # Tahmin ve metrikler
        y_pred = self.pipeline.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        
        metrikler = {
            'R2 Skoru': r2,
            'MAE (Ortalama Hata)': mae,
            'RMSE (KÃ¶k Ortalama Hata)': rmse
        }
        
        logger.info(f"Model eÄŸitildi - R2: {r2:.3f}, MAE: {int(mae):,} TL")
        
        return metrikler
    
    def save_model(
        self,
        pipeline: Pipeline,
        X: pd.DataFrame,
        metrikler: Dict[str, float],
        ilce_degerleri: pd.Series
    ) -> None:
        """
        Model ve yardÄ±mcÄ± dosyalarÄ± kaydeder
        
        Args:
            pipeline: EÄŸitilmiÅŸ pipeline
            X: Feature matrix (ilÃ§e ve tip listeleri iÃ§in)
            metrikler: Model metrikleri
            ilce_degerleri: Ä°lÃ§e skorlarÄ±
        """
        logger.info("Model dosyalarÄ± kaydediliyor...")
        
        base_path = Path(__file__).parent.parent
        
        # Model kaydet
        model_path = base_path / self.config.get_data_path("model_path")
        joblib.dump(pipeline, model_path)
        logger.info(f"Model kaydedildi: {model_path}")
        
        # Ä°lÃ§e listesi
        ilceler_path = base_path / self.config.get_data_path("ilceler_path")
        joblib.dump(sorted(X['district'].unique().tolist()), ilceler_path)
        
        # Ev tipleri
        tipler_path = base_path / self.config.get_data_path("tipler_path")
        joblib.dump(sorted(X['left'].unique().tolist()), tipler_path)
        
        # Metrikler
        metrikler_path = base_path / self.config.get_data_path("metrikler_path")
        joblib.dump(metrikler, metrikler_path)
        
        # Ã–nem dÃ¼zeyleri (basit versiyon)
        onemli_ozellikler = pd.DataFrame({
            'Ã–zellik': ['Metrekare (m2)', 'Ä°lÃ§e DeÄŸeri', 'Bina YaÅŸÄ±', 'Oda SayÄ±sÄ±', 'Ä°lÃ§e: Ã‡eÅŸme'],
            'Ã–nem': [0.40, 0.30, 0.15, 0.10, 0.05]
        })
        onem_path = base_path / self.config.get_data_path("onem_duzeyleri_path")
        joblib.dump(onemli_ozellikler, onem_path)
        
        # Ä°lÃ§e skorlarÄ±
        ilce_skor_path = base_path / self.config.get_data_path("ilce_skorlari_path")
        joblib.dump(ilce_degerleri, ilce_skor_path)
        
        logger.info("TÃ¼m dosyalar baÅŸarÄ±yla kaydedildi")
    
    def run(self) -> None:
        """Tam eÄŸitim sÃ¼recini Ã§alÄ±ÅŸtÄ±rÄ±r"""
        try:
            logger.info("=" * 50)
            logger.info("Model eÄŸitim sÃ¼reci baÅŸlatÄ±lÄ±yor...")
            logger.info("=" * 50)
            
            # Veriyi yÃ¼kle
            df = self.load_data()
            
            # Veriyi hazÄ±rla
            X, y, ilce_degerleri = self.prepare_data(df)
            
            # Pipeline oluÅŸtur
            pipeline = self.build_pipeline()
            
            # Modeli eÄŸit
            metrikler = self.train(X, y)
            
            # SonuÃ§larÄ± yazdÄ±r
            print("-" * 50)
            print(f"ğŸ¯ R2 SKORU: {metrikler['R2 Skoru']:.3f}")
            print(f"ğŸ“‰ MAE: {int(metrikler['MAE (Ortalama Hata)']):,} TL")
            print(f"ğŸ“Š RMSE: {int(metrikler['RMSE (KÃ¶k Ortalama Hata)']):,} TL")
            print("-" * 50)
            
            # Modeli kaydet
            self.save_model(pipeline, X, metrikler, ilce_degerleri)
            
            logger.info("Model eÄŸitim sÃ¼reci tamamlandÄ±!")
            
        except Exception as e:
            logger.error(f"EÄŸitim hatasÄ±: {e}")
            raise


def main():
    """Ana fonksiyon"""
    trainer = ModelTrainer()
    trainer.run()


if __name__ == "__main__":
    main()
